import random

from sklearn.cluster import KMeans

from typing import Dict, List, Tuple
import numpy as np
from scipy.optimize import differential_evolution
from sklearn.preprocessing import StandardScaler

from 日志管理 import 日志记录器



def 准备RBF训练数据(入库流量: np.ndarray, 动态库容时序序列: np.ndarray, 需水量: np.ndarray,
                    是预报: bool, 最小放水量:float, 最大泄洪量:float,
                    库容调节系数:float, 最小库容:float, 最大库容:float) -> Tuple[Dict[str, np.ndarray], np.ndarray]:
    """
    构造 RBF 训练数据 (X, y)，适用于有预报 & 无预报模式

    参数:
        数据容器: 包含 inflow, storages, demand 等数据的容器

    返回:
        元组 (特征字典, 目标值数组)
    """
    总长度 = len(入库流量)
    样本数 = 总长度  # TODO: 直接使用完整数据长度作为样本数，这是否合理？

    # 构造 入库流量 矩阵 (样本数 × 3)
    入流矩阵 = np.zeros((样本数, 3))
    # 赋值 TODO: 这个赋值是基于什么考量？
    for 时间点 in range(样本数):
        入流矩阵[时间点, 0] = 入库流量[时间点]
        if 时间点 + 1 < 总长度:
            入流矩阵[时间点, 1] = 入库流量[时间点 + 1]
        else:
            入流矩阵[时间点, 1] = 入库流量[-1]
        if 时间点 + 2 < 总长度:
            入流矩阵[时间点, 2] = 入库流量[时间点 + 2]
        else:
            入流矩阵[时间点, 2] = 入库流量[-1]

    # 构造趋势特征 (差分)
    趋势 = np.diff(入库流量)
    趋势 = np.concatenate([趋势, [0]])  # 用 0 填充最后一个趋势值

    # 构造特征字典 取样本数个数据
    特征字典 = {
        "当前库容": 动态库容时序序列[0:样本数].flatten(),
        "入库流量": 入流矩阵,
        "需水量": 需水量[0:样本数].flatten(),
        # 计算出来的趋势
        "流量趋势": 趋势
    }
    if 是预报:
        # 获取两个最优参数
        alpha,beta = 获取最优参数(入库流量, 动态库容时序序列, 最小放水量, 最大泄洪量, 库容调节系数)
        临时目标列表 = []
        # 2. 遍历每个时间步
        # TODO： 这真的是在遍历每个时间步吗？
        for 样本 in range(样本数):
            # 准备计算参数
            当前预报 = [float(入流矩阵[样本, 1]), float(入流矩阵[样本, 2])]
            当前库容 = 动态库容时序序列[样本]
            当前入流 = 入库流量[样本]
            加权预报 = 计算指数衰减加权(当前预报,0.6)
            基础放水量 = alpha * 加权预报 + beta * 当前入流 + 库容调节系数 * 当前库容
            # 进行约束代码
            当前需水量 = float(需水量[样本])
            # TODO: 这里真的是调整了吗
            # 判断本次样本最小放水量是多少，如果当前需水量较大，至少要满足当前需水量
            本次样本最小放水量 = max(当前需水量, 最小放水量)
            # 将泄洪能力限制在 本次样本最小放水量 < 实际放水量 < 最大泄洪能力
            本次样本最小放水量 = np.clip(基础放水量, 本次样本最小放水量, int(最大泄洪量))
            # 判断泄洪之后的库容，如果泄洪后小于最小库容，那就只允许它泄洪到最小库容
            # 因而有 最低库容 + 本次出流 - 本次入流 = 当前库容
            放水后的库容 = 当前库容 + 当前入流 - 本次样本最小放水量
            if 放水后的库容 < 最小库容:
                本次样本最小放水量 = 当前库容 + 当前入流 - 最小库容
            elif 放水后的库容 > 最大库容:
                本次样本最小放水量 = 当前库容 + 当前入流 - 最大库容
            临时目标列表.append(本次样本最小放水量)
        # 3. 转换为numpy数组
        放水量时间序列 = np.array(临时目标列表)
    else:
        # TODO: 请问这个0.6代表什么？是经验公式吗
        放水量时间序列 = 0.6 * 入库流量[0:样本数]

    return 特征字典,放水量时间序列

def 准备预报的训练数据(入库流量: np.ndarray, 动态库容时序: np.ndarray) -> List[Dict]:
    """从数据容器中提取历史数据构建训练集"""
    训练数据列表 = []
    for 时间点 in range(len(入库流量) - 2):  # 确保未来两期预报存在
        训练数据列表.append({
            "预报数据": [
                入库流量[时间点 + 1],  # t+1 实际流量（作为历史预报值）
                入库流量[时间点 + 2]  # t+2 实际流量
            ],
            # TODO: 这应该是当前的数据罢，我应该没理解错
            "当前入库流量": 入库流量[时间点],
            "当前动态库容": 动态库容时序[时间点]
        })
    return 训练数据列表


def 计算指数衰减加权(预报列表: List[float], 衰减系数: float = 0.6) -> float:
    """
    指数衰减权重计算（近期权重更高）

    参数:
        预报列表: 预报值列表，按时间顺序排列（最近的在最后）
        衰减系数: 权重衰减系数，默认0.6

    返回:
        加权平均后的预报值
    """
    权重列表 = [衰减系数 ** i for i in range(len(预报列表))]
    return np.dot(预报列表, 权重列表) / sum(权重列表)


def 差分进化算法调用的目标求解函数(参数: np.ndarray, 训练数据列表: List[Dict], 最小放水量, 最大泄洪能力,
                                   库容调节系数) -> float:
    """优化目标函数（最小化负放水量总和）"""
    α, β = 参数
    总放水量 = 0.0

    for 单个训练数据 in 训练数据列表:
        # 计算加权预报值（默认使用指数衰减）
        加权预报 = 计算指数衰减加权(单个训练数据["预报数据"])

        # 计算放水量
        放水量 = (
                α * 加权预报 +
                β * 单个训练数据["当前入库流量"] +
                库容调节系数 * 单个训练数据["当前动态库容"]
        )

        # 检查约束
        if not (最小放水量 <= 放水量 <= 最大泄洪能力):
            日志记录器.warn("发现本次放水量为{},已超出约束".format(放水量))
            return 1e15  # 惩罚非法解

        总放水量 += 放水量

    return -总放水量  # 最小化负值 = 最大化放水量


def 获取最优参数(入库流量: np.ndarray, 动态库容时序: np.ndarray, 最小放水量, 最大泄洪能力, 库容调节系数) -> Tuple[
    float, float]:
    """
    返回最优参数 (α, β)
    优化目标：最大化总放水量，且满足约束条件
    """
    训练数据集 = 准备预报的训练数据(入库流量, 动态库容时序)
    print(f"训练数据样本量: {len(训练数据集)}")
    print("首条训练数据:", 训练数据集[0])

    参数范围 = [(0.2, 0.8), (0.1, 0.5)]  # α和β的搜索区间

    # 这里用的是差分进化算法
    优化结果 = differential_evolution(
        # 这里的封装就是说看上去传参了一个参数，实际上是传参了多个参数的意思，这是匿名函数。
        lambda 参数: 差分进化算法调用的目标求解函数(参数, 训练数据集, 最小放水量, 最大泄洪能力, 库容调节系数),
        参数范围,
        strategy='best1bin',
        maxiter=50,
        popsize=10
    )
    print("搜索最优参数的结果为：" + str(优化结果.message))
    return round(优化结果.x[0], 3), round(优化结果.x[1], 3)  # 保留3位小数


def 获取特征矩阵(
        输入特征: Dict[str, np.ndarray],
        特征模式: str
) -> np.ndarray:
    """根据配置模式选择输入特征

    参数:
        RBF网络: RBF网络字典
        输入特征: 包含以下键的字典:
            - 当前库容: 形状 [n_samples]
            - 入库流量: 形状 [n_samples, n_timesteps]
            - 需水量: 形状 [n_samples]
            - 流量趋势: 形状 [n_samples]
        特征模式: "无预报"或"有预报"

    返回:
        特征矩阵 [n_samples, n_features]
    """
    必需特征 = ["当前库容", "入库流量", "需水量", "流量趋势"]
    for 特征名 in 必需特征:
        if 特征名 not in 输入特征:
            raise ValueError(f"输入特征缺失必需的键: {特征名}")

    样本数 = len(输入特征["当前库容"])
    # 验证数据维度一致性
    if (输入特征["入库流量"].shape[0] != 样本数 or
            输入特征["需水量"].shape[0] != 样本数 or
            输入特征["流量趋势"].shape[0] != 样本数):
        raise ValueError("输入特征维度不一致")

    if 特征模式 == "无预报":
        # 无预报模式：[当前库容, 当前入库流量, 需水量]
        return np.column_stack([
            输入特征["当前库容"],
            输入特征["入库流量"][:, 0],  # 当前时刻流量
            输入特征["需水量"]
        ])
    else:
        # 有预报模式需要至少3个时段的入库流量数据
        if 输入特征["入库流量"].shape[1] < 3:
            raise ValueError("有预报模式需要至少3个时段的入库流量数据")

        # [当前库容, 当前流量, 需水量, 趋势, 未来2时段预报]
        return np.column_stack([
            输入特征["当前库容"],
            输入特征["入库流量"][:, 0],
            输入特征["需水量"],
            # TODO：可能需要修正
            输入特征["流量趋势"],
            输入特征["入库流量"][:, 1],  # t+1预报
            输入特征["入库流量"][:, 2]  # t+2预报
        ])


from sklearn.preprocessing import StandardScaler


def 水库特征标准化(特征矩阵):
    """
    分组标准化处理水库调度特征矩阵
    输入: [库容,当前流量,需水量,趋势,t+1预报,t+2预报]
    输出: 分组标准化后的矩阵
    """
    # 第一组：库容（单独处理，使用Robust Scaling）
    库容_scaled = (特征矩阵[:, 0] - np.median(特征矩阵[:, 0])) / \
                  (np.percentile(特征矩阵[:, 0], 75) - np.percentile(特征矩阵[:, 0], 25))

    # 第二组：流量相关特征（当前流量 + 预报）
    流量组 = 特征矩阵[:, [1, 4, 5]]  # 当前流量, t+1, t+2
    流量组_scaled = StandardScaler().fit_transform(流量组)

    # 第三组：需水量+趋势（需水量保持与流量的关系）
    需水量_scaled = (特征矩阵[:, 2] - np.mean(特征矩阵[:, 2])) / np.std(特征矩阵[:, 2])
    趋势_scaled = (特征矩阵[:, 3] - np.mean(特征矩阵[:, 3])) / np.std(特征矩阵[:, 3])

    return np.column_stack([
        库容_scaled,
        流量组_scaled[:, 0],  # 当前流量
        需水量_scaled,
        趋势_scaled,
        流量组_scaled[:, 1],  # t+1
        流量组_scaled[:, 2]  # t+2
    ])


def 训练RBF网络(
        隐含层节点数: int,
        输入特征: Dict[str, np.ndarray],
        目标输出: np.ndarray,
        特征模式: str
):
    """训练RBF网络

    参数:
        RBF网络: RBF网络字典
        输入特征: 输入特征字典
        目标输出: 目标输出（放水量）形状 [n_samples] 或 [n_samples, n_outputs]
        特征模式: "no_forecast"或"with_forecast"
    """
    if 目标输出.size == 0:
        raise ValueError("目标输出不能为空")
    if 目标输出.ndim == 1:
        目标输出 = 目标输出.reshape(-1, 1)  # 转换为二维数组

    # 1. 特征选择与预处理
    特征矩阵 = 获取特征矩阵(输入特征, 特征模式)
    样本数, 特征数 = 特征矩阵.shape
    # // AI添加 - 特征矩阵基础信息检查
    print("// AI添加 - 特征矩阵检查")
    print(f"特征矩阵形状: ({样本数}, {特征数})")
    print("各列特征范围:")
    print(f"当前库容: [{np.min(特征矩阵[:,0]):.1f}, {np.max(特征矩阵[:,0]):.1f}]")
    print(f"当前流量: [{np.min(特征矩阵[:,1]):.1f}, {np.max(特征矩阵[:,1]):.1f}]")
    print(f"需水量: [{np.min(特征矩阵[:,2]):.1f}, {np.max(特征矩阵[:,2]):.1f}]")
    print(f"流量趋势: [{np.min(特征矩阵[:,3]):.2f}, {np.max(特征矩阵[:,3]):.2f}]")
    print(f"t+1预报: [{np.min(特征矩阵[:,4]):.1f}, {np.max(特征矩阵[:,4]):.1f}]")
    print(f"t+2预报: [{np.min(特征矩阵[:,5]):.1f}, {np.max(特征矩阵[:,5]):.1f}]")

    特征矩阵_标准化 = 水库特征标准化(特征矩阵)

    print("标准化后特征范围:")
    print(f"库容: [{np.min(特征矩阵_标准化[:, 0]):.2f}, {np.max(特征矩阵_标准化[:, 0]):.2f}]")
    print(f"当前流量: [{np.min(特征矩阵_标准化[:, 1]):.2f}, {np.max(特征矩阵_标准化[:, 1]):.2f}]")
    print(f"需水量-流量比: {np.mean(特征矩阵_标准化[:, 2] / (特征矩阵_标准化[:, 1] + 1e-6)):.2f}")

    # 2. K-Means聚类确定中心点
    kmeans = KMeans(
        n_clusters=隐含层节点数,
        n_init=10
    )
    kmeans.fit(特征矩阵)
    聚类的中心点 = kmeans.cluster_centers_

    # 3. 计算宽度参数（标准差 + 平滑项）
    聚类标签 = kmeans.labels_
    宽度参数 = np.zeros((隐含层节点数, 特征数))

    for i in range(隐含层节点数):
        簇数据 = 特征矩阵[聚类标签 == i]
        if 簇数据.size == 0:
            # 处理空簇：使用全局标准差
            全局标准差 = np.std(特征矩阵, axis=0) + 1e-6
            宽度参数[i] = 全局标准差
        else:
            宽度参数[i] = np.std(簇数据, axis=0) + 1e-6

    # TODO 进一步研究这个是处理了什么
    处理完毕的宽度参数 = 宽度参数

    # 4. 计算径向基矩阵
    phi = 计算径向基矩阵(聚类的中心点, 处理完毕的宽度参数, 特征矩阵)

    # 5. 求解权重（最小二乘法）
    try:
        输出权重 = np.linalg.lstsq(phi, 目标输出, rcond=1e-6)[0]
    except np.linalg.LinAlgError as e:
        raise RuntimeError(f"权重求解失败: {str(e)}") from e
    return {
        "中心点": 聚类的中心点,
        "宽度参数": 处理完毕的宽度参数,
        "输出权重": 输出权重
    }


def 计算径向基矩阵(中心点, 宽度参数, 特征矩阵: np.ndarray) -> np.ndarray:
    """计算径向基函数激活矩阵"""
    差值 = 特征矩阵[:, np.newaxis] - 中心点
    缩放差值 = 差值 / 宽度参数
    平方距离 = np.sum(缩放差值 ** 2, axis=2)
    # 避免指数爆炸
    平方距离 = np.clip(平方距离, 0, 100)
    return np.exp(-平方距离)


def 预测输出(
        中心点,
        宽度参数,
        输出权重,
        输入特征: Dict[str, np.ndarray],
        模式: str
) -> np.ndarray:
    # TODO: 进一步研究确认
    """使用RBF网络进行预测"""
    特征矩阵 = 获取特征矩阵(输入特征, 模式)
    phi = 计算径向基矩阵(中心点, 宽度参数, 特征矩阵)
    预测值 = phi @ 输出权重
    if 预测值.shape[1] == 1:
        return 预测值.squeeze(axis=1)
    else:
        return 预测值

def 根据RBF预测函数生成多组数据(中心点,宽度参数,输出权重,
                                输入特征,模式,
                                生成数量:int=50,
                                噪声标准差:float = 0.01) ->np.ndarray:
    # 初始化结果容器 结果应该和输入特征是一样的，只不过有 {生成数量} 个
    所有预测结果 = []

    # 获取样本数量（以第一个特征的长度为准）
    样本数 = len(next(iter(输入特征.values())))

    for _ in range(生成数量):
        # 添加噪声，从而让数据发生一定的变化
        扰动后特征 = {
            k: v + np.random.normal(0, 噪声标准差, v.shape)
            for k, v in 输入特征.items()
        }

        # 2. 使用RBF模型预测
        原始预测 = 预测输出(中心点,宽度参数,输出权重,扰动后特征,模式)

        # 3. 三点滑动平均平滑
        平滑预测 = []
        for i in range(样本数):
            # 边界处理
            左 = max(0, i - 1)
            右 = min(样本数 - 1, i + 1)
            邻域 = 原始预测[左: 右 + 1]
            平滑值 = sum(邻域) / len(邻域)
            平滑预测.append(平滑值)

        所有预测结果.append(平滑预测)

    return 所有预测结果
